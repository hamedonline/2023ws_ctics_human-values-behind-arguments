{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "print(locale.getpreferredencoding())\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "qqbtlQokNe-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers torch accelerate"
      ],
      "metadata": {
        "id": "p3B2yUOGNL-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "_6AfgF3_arYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model, use_auth_token=True)"
      ],
      "metadata": {
        "id": "jsBrtGpZYmcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "llama_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "0AqJo1R_a9IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_llama_response(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate a response from the Llama model.\n",
        "\n",
        "    Parameters:\n",
        "        prompt (str): The user's input/question for the model.\n",
        "\n",
        "    Returns:\n",
        "        response (str): return the model's response.\n",
        "    \"\"\"\n",
        "    sequences = llama_pipeline(\n",
        "        text_inputs=prompt,\n",
        "        return_full_text=False,\n",
        "        do_sample=True,\n",
        "        top_k=10,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "\n",
        "    )\n",
        "    print(\"Chatbot:\", sequences[0]['generated_text'])\n",
        "    return sequences[0]['generated_text']\n"
      ],
      "metadata": {
        "id": "m8RwW7Axcu9E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"webis/Touche23-ValueEval\")\n",
        "initial_prompt_1 = \"\"\"\n",
        "\n",
        "<s>[INST] <<SYS>>\n",
        "{{ Imagine you are a psychologist. It is your job to analyze the human values behind a list of arguments provided to you.\n",
        "\n",
        "An argument is given as a triple: ( , , ). The premise is the statement given to the person. The stance describes what the person thinks of the premise (either pro or contra). In the justification, the person explains the reasoning behind their stance.\n",
        "\n",
        "For each argument, we want a list of human values that best explains the person's reasoning. Specifically, we use the values proposed by Kiesel et al. in their paper \"Identifying the Human Values behind Arguments\" from 2022. If you did not come across this paper, here are the values and a short definition:\n",
        "\n",
        "- thought: it is good to have own ideas and interests\n",
        "- action: it is good to determine one's own actions\n",
        "- stimulation: it is good to experience excitement, novelty, and change\n",
        "- hedonism: it is good to experience pleasure and sensual gratification\n",
        "- achievement: it is good to be successful in accordance with social norms\n",
        "- dominance: it is good to be in positions of control over others\n",
        "- resources: it is good to have material possessions and social resources\n",
        "- face: it is good to maintain one's public image\n",
        "- personal: it is good to have a secure immediate environment\n",
        "- society: it is good to have a secure and stable wider society\n",
        "- tradition: it is good to maintain cultural, family, or religious traditions\n",
        "- rules: it is good to comply with rules, laws, and formal obligations\n",
        "- interpersonal: it is good to avoid upsetting or harming others\n",
        "- humility: it is good to recognize one's own insignificance in the larger scheme of things\n",
        "- caring: it is good to work for the welfare of one's group's members\n",
        "- dependability: it is good to be a reliable and trustworthy member of one's group\n",
        "- concern: it is good to strive for equality, justice, and protection for all people\n",
        "- nature: it is good to preserve the natural environment\n",
        "- tolerance: it is good to accept and try to understand those who are different from oneself\n",
        "- objectivity: it is good to search for the truth and think in a rational and unbiased way\n",
        "\n",
        "Here are a few examples:\n",
        "\n",
        "- Input: (\"We should end the use of economic sanctions\", contra, \"Economic sanctions provide security and ensure that citizens are treated fairly\")\n",
        "- Your response: (societal, concern)\n",
        "\n",
        "- Input: (\"We need a better migration policy\", pro, \"Discussing what happened in the past between Africa and Europe is useless. All slaves and their owners died a long time ago. You cannot blame the grandchildren\")\n",
        "- Your response: (concern)\n",
        "\n",
        "- Input: (\"Rapists should be tortured\", contra, \"Throughout India, many false rape cases are being registered these days. Torturing all of the accused persons causes torture to innocent persons too.\")\n",
        "- Your response: (societal, concern)\n",
        "\n",
        "Only return the labels, no explanation is required. Also dont write the triplet in front of the labels.\n",
        "When receiving several triplets in this form:\n",
        "(x1,y1,z1)\n",
        "(x2,y2,z2)\n",
        "(x3,y3,z3)\n",
        "\n",
        "answer in this format:\n",
        "(label_1.1, label_1.2)\n",
        "(label_2.1, label_2.2)\n",
        "(label_3.1, label_3.2)\n",
        "\n",
        "DO NOT ADD ANYTHING ELSE TO YOUR ANSWER!\n",
        "\n",
        "Here are the triplets:}}\n",
        "<</SYS>>\n",
        "\n",
        "{{user_prompt}} [/INST]\n",
        "\"\"\"\n",
        "def get_prompt(argument):\n",
        "    conc = argument[\"Conclusion\"]\n",
        "    stance = argument[\"Stance\"]\n",
        "    prem = argument[\"Premise\"]\n",
        "    return f\"(\\\"{conc}\\\", {stance}, \\\"{prem}\\\")\""
      ],
      "metadata": {
        "id": "B8DVyIHXMFpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# change prompt here\n",
        "initial_prompt = initial_prompt_1\n",
        "counter = 0\n",
        "shift = 0\n",
        "while counter < 300:\n",
        "    triplets = \"\"\n",
        "    for i in range(10):\n",
        "        if counter < len(dataset[\"test\"]):\n",
        "            triplets += get_prompt(dataset[\"test\"][counter + shift]) + \"\\n\"\n",
        "            counter += 1\n",
        "    prompt = initial_prompt.replace(\"{{user_prompt}}\",triplets)\n",
        "\n",
        "    errors = 0\n",
        "    while errors < 10:\n",
        "        try:\n",
        "            response =get_llama_response(prompt)\n",
        "            with open('results' + str(counter + shift) + '.txt', 'w') as file:\n",
        "                file.write(response)\n",
        "            break  # Break out of the loop if successful\n",
        "        except Exception as e:\n",
        "            print(f\"An exception occurred: {e}\")\n",
        "            print(\"Waiting for 10 seconds before retrying...\")\n",
        "            time.sleep(10)\n",
        ""
      ],
      "metadata": {
        "id": "lFeFgF_vM5PL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}